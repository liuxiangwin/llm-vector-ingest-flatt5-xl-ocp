{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5efb44b5-ffd8-4846-bf43-0baba85c4738",
   "metadata": {},
   "source": [
    "## Example of querying a set of documents with sources using the Hugging Face Text Generation Inference server with Llama2, Langchain and a custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563bd823-e3a8-4142-83c9-15c3421b88bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/app-root/lib/python3.9/site-packages (0.2.11)\n",
      "Requirement already satisfied: pypdf in /opt/app-root/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: sentence-transformers in /opt/app-root/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: chromadb==0.3.29 in /opt/app-root/lib/python3.9/site-packages (0.3.29)\n",
      "Requirement already satisfied: text_generation in /opt/app-root/lib/python3.9/site-packages (0.6.1)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (1.0.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (0.30.3)\n",
      "Requirement already satisfied: pandas>=1.3 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (2.2.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (4.12.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (7.7.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (1.10.17)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (1.26.4)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (0.19.1)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (0.7.17)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (3.5.0)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (0.8.0)\n",
      "Requirement already satisfied: fastapi==0.85.1 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (0.85.1)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (4.66.4)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/app-root/lib/python3.9/site-packages (from chromadb==0.3.29) (1.18.1)\n",
      "Requirement already satisfied: starlette==0.20.4 in /opt/app-root/lib/python3.9/site-packages (from fastapi==0.85.1->chromadb==0.3.29) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/app-root/lib/python3.9/site-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (4.4.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/app-root/lib/python3.9/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/app-root/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/app-root/lib/python3.9/site-packages (from langchain) (0.2.24)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/app-root/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/app-root/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/app-root/lib/python3.9/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/app-root/lib/python3.9/site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/app-root/lib/python3.9/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (4.43.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (2.2.2+cu121)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib/python3.9/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.6.2)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/app-root/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2.2.2)\n",
      "Requirement already satisfied: zstandard in /opt/app-root/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (0.23.0)\n",
      "Requirement already satisfied: lz4 in /opt/app-root/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (4.3.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/app-root/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/app-root/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: coloredlogs in /opt/app-root/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/app-root/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/app-root/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (4.25.3)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from pandas>=1.3->chromadb==0.3.29) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib/python3.9/site-packages (from pandas>=1.3->chromadb==0.3.29) (2024.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/app-root/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.28->chromadb==0.3.29) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.28->chromadb==0.3.29) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/app-root/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/app-root/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (8.1.7)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.22.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.6.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/app-root/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/app-root/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.29) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/app-root/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.29) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain pypdf sentence-transformers chromadb==0.3.29 text_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a196e07-7980-43f3-906e-7373367fe896",
   "metadata": {},
   "source": [
    "### Set the Inference server url (replace with your own address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aaedb0b-4a37-418e-9608-8abcc819f87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inference_server_url_flant5_xl = \"http://hf-flant5-xl.llm-model-collection.svc.cluster.local:3000/\"\n",
    "# inference_server_url_mistral = \"http://hf-mistral-7b.llm-model-collection.svc.cluster.local:3000/\"\n",
    "\n",
    "\n",
    "inference_server_url_flant5_xl = \"http://hf-text-generation-inference-server.llm-flan-t5-xl.svc.cluster.local:3000/\"\n",
    "inference_server_url_llama2 = \"http://hf-generation-is.llama-2-7b-chat-hf-fine-tuned.svc.cluster.local:3000/\"\n",
    "\n",
    "COLLECTION_NAME = \"documents_test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fbc3e3-6612-49eb-b07e-710e27f4d2df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load some data from the folder where we have stored the PDF documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31f9b89-3613-42fc-aa6f-683ac78accff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "pdf_folder_path = 'rhods-doc'\n",
    "\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4547b1-4dea-4c08-ad79-c70186f25611",
   "metadata": {},
   "source": [
    "### Split the data in chunks large enough to have meaningful answers, and some overlap not to miss anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7a68c1-2308-410e-b50f-9270c00b1d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1024, chunk_overlap = 40)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e32e34-aa32-4a57-b4ac-3e2e490b1be6",
   "metadata": {},
   "source": [
    "### Store the data as embeddings in a vector database (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af325249-120a-49e4-be21-5b902e054819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/opt/app-root/lib64/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                    embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34903f71-99cc-4d4d-a97a-dc530e9c5a47",
   "metadata": {},
   "source": [
    "### Test data retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb47f639-98bc-4f59-b6b6-56e01affb708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'rhods-doc/red_hat_openshift_data_science_self-managed-1.32-getting_started_with_red_hat_openshift_data_science_self-managed-en-us.pdf', 'page': 12}, page_content='-\\n, and must start and end with an alphanumeric\\ncharacter.\\n5\\n. \\nEnter a \\ndescription\\n for your data science project.\\n6\\n. \\nClick \\nCreate\\n.\\nA project details page opens. From here, you can create workbenches, add cluster storage, and\\nadd data connections to your project.\\nVerification\\nThe data science project that you created is displayed on the \\nData science projects\\n page.\\nCHAPTER 4. CREATING A DATA SCIENCE PROJECT\\n9'),\n",
       " Document(metadata={'source': 'rhods-doc/red_hat_openshift_data_science_self-managed-1.32-working_on_data_science_projects-en-us.pdf', 'page': 14}, page_content='-\\n, and must start and end with an alphanumeric\\ncharacter.\\n5\\n. \\nEnter a \\ndescription\\n for your data science project.\\n6\\n. \\nClick \\nCreate\\n.\\nA project details page opens. From here, you can create workbenches, add cluster storage, and\\nCHAPTER 3. WORKING ON DATA SCIENCE PROJECTS\\n11'),\n",
       " Document(metadata={'source': 'rhods-doc/red_hat_openshift_data_science_self-managed-1.32-getting_started_with_red_hat_openshift_data_science_self-managed-en-us.pdf', 'page': 12}, page_content='CHAPTER 4. CREATING A DATA SCIENCE PROJECT\\nTo start your data science work, create a data science project. Creating a project helps you organize your\\nwork in one place. You can also enhance the capabilities of your data science project by adding\\nworkbenches, adding storage to your project’s cluster, adding data connections, and adding model\\nservers.\\nPrerequisites\\nYou have logged in to Red Hat OpenShift Data Science.\\nIf you are using specialized OpenShift Data Science groups, you are part of the user group or\\nadmin group (for example, \\nrhods-users\\n or \\nrhods-admin\\n ) in OpenShift.\\nProcedure\\n1\\n. \\nFrom the OpenShift Data Science dashboard, click \\nData Science Projects\\n.\\nThe \\nData science projects\\n page opens.\\n2\\n. \\nClick \\nCreate data science project\\n.\\nThe \\nCreate a data science project\\n dialog opens.\\n3\\n. \\nEnter a \\nname\\n for your data science project.\\n4\\n. \\nOptional: Edit the \\nresource name\\n for your data science project. The resource name must\\nconsist of lowercase alphanumeric characters, \\n-'),\n",
       " Document(metadata={'source': 'rhods-doc/red_hat_openshift_data_science_self-managed-1.32-working_on_data_science_projects-en-us.pdf', 'page': 14}, page_content='3.1.1. Creating a data science project\\nTo start your data science work, create a data science project. Creating a project helps you organize your\\nwork in one place. You can also enhance the capabilities of your data science project by adding\\nworkbenches, adding storage to your project’s cluster, adding data connections, and adding model\\nservers.\\nPrerequisites\\nYou have logged in to Red Hat OpenShift Data Science.\\nIf you are using specialized OpenShift Data Science groups, you are part of the user group or\\nadmin group (for example, \\nrhods-users\\n or \\nrhods-admin\\n ) in OpenShift.\\nProcedure\\n1\\n. \\nFrom the OpenShift Data Science dashboard, click \\nData Science Projects\\n.\\nThe \\nData science projects\\n page opens.\\n2\\n. \\nClick \\nCreate data science project\\n.\\nThe \\nCreate a data science project\\n dialog opens.\\n3\\n. \\nEnter a \\nname\\n for your data science project.\\n4\\n. \\nOptional: Edit the \\nresource name\\n for your data science project. The resource name must\\nconsist of lowercase alphanumeric characters, \\n-')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I create a Data Science Project\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4dd9a-9ac0-407a-9455-0a5906aa9ed3",
   "metadata": {},
   "source": [
    "### Create the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda3cceb-2c39-4a74-bf72-a733b22dfd22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceTextGenInference` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# NOTE: This template syntax is specific to Llama2\n",
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant.\n",
    "You will be given a question you need to answer, and a context to provide you with information. You must answer the question based as much as possible on this context.\n",
    "Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Question: {question}\n",
    "Context: {context} [/INST]\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm_flant5_xl = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url_llama2,\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.175,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "qa_chain_llm_flant5 = RetrievalQA.from_chain_type(llm_flant5_xl,\n",
    "                                       retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "                                       return_source_documents=True)\n",
    "\n",
    "\n",
    "\n",
    "llm_mistral = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url_flant5_xl,\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.175,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "qa_chain_mistral = RetrievalQA.from_chain_type(llm_mistral,\n",
    "                                       retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "                                       return_source_documents=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9562872b-eff8-4698-afb1-fc634a1a3054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a data science project involves several steps, which are outlined below:\n",
      "\n",
      "1. Log in to Red Hat OpenShift Data Science: Before creating a data science project, you need to log in to your OpenShift account. If you are using specialized OpenShift Data Science groups, you must be part of the user group or admin group (e.g., rhods-users or rhods-admin) in OpenShift.\n",
      "2. Click on \"Data Science Projects\": Once you are logged in, navigate to the OpenShift Data Science dashboard and click on \"Data Science Projects.\" This will take you to the \"Data Science Projects\" page.\n",
      "3. Click on \"Create Data Science Project\": On the \"Data Science Projects\" page, click on the \"Create Data Science Project\" button. This will open the \"Create a Data Science Project\" dialog box.\n",
      "4. Enter a Name for your Project: In step 3, enter a unique name for your data science project. Make sure the name consists of lowercase alphanumeric characters only (-).\n",
      "5. Optional: Edit Resource Name: You can edit the resource name for your data science project if needed. The resource name must consist of lowercase alphanumeric characters only (-).\n",
      "6. Click Create: After entering the required details, click on the \"Create\" button to create your data science project.\n",
      "7. Add Workbenches, Cluster Storage, Data Connections, and Model Servers: Once your data science project is created, you can enhance its capabilities by adding workbenches, adding storage to your project's cluster, adding data connections, and adding model servers. These additional features will enable you to perform various data science tasks more efficiently.\n",
      "\n",
      "By following these steps, you can successfully create a data science project in Red Hat OpenShift Data Science."
     ]
    }
   ],
   "source": [
    "question = \"How do I create a Data Science Project?\"\n",
    "result = qa_chain_llm_flant5({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03510738-5704-4b56-9ce8-db99d0259757",
   "metadata": {},
   "source": [
    "### Launch the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb26a45d-7953-42cb-aab5-cf2e8c63213d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To start your data science work, create a data science project. Creating a project helps you organize your work in one place. You can also enhance the capabilities of your data science project by adding workbenches, adding storage to your project’s cluster, adding data connections, and adding model servers. Prerequisites You have logged in to Red Hat OpenShift Data Science. If you are using specialized OpenShift Data Science groups, you are part of the user group or admin group (for example, rhods-users or rhods-admin) in OpenShift. Procedure 1 . From the OpenShift Data Science dashboard, click Data Science Projects . The Data science projects page opens. 2 . Click Create data science project . The Create a data science project dialog opens. 3 . Enter a name for your data science project. 4 . Optional: Edit the resource name for your data science project. The resource name must consist of lowercase alphanumeric characters, - 3.1.1. Creating a data science project To start your data science work, create a data science project. Creating a project helps you organize your work in one place. You can also enhance the capabilities of your data science project by adding workbenches, adding storage to your project’s cluster, adding data connections, and adding model servers. Prerequisites You have logged in to Red Hat OpenShift Data Science. If you are using specialized OpenShift Data Science groups, you are part of the user group or admin group (for example, rhods-users or rhods-admin) in OpenShift. Procedure 1 . From the OpenShift Data Science dashboard, click Data Science Projects . The Data science projects page opens. 2 . Click Create data science project . The Create a data science project dialog opens. 3 . Enter a name for your data science project. 4 . Optional: Edit the resource name for your data science project. The resource name must consist of lowercase alphanumeric characters, -"
     ]
    }
   ],
   "source": [
    "question = \"How do I create a Data Science Project?\"\n",
    "result = qa_chain_mistral({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b28ac-a3ab-462c-add7-e5473eaea92f",
   "metadata": {},
   "source": [
    "### Print the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07166717-6b89-47de-baab-f91695602e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhods-doc/red_hat_openshift_data_science_self-managed-1.32-getting_started_with_red_hat_openshift_data_science_self-managed-en-us.pdf\n",
      "rhods-doc/red_hat_openshift_data_science_self-managed-1.32-working_on_data_science_projects-en-us.pdf\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item.metadata['source'] not in unique_list:\n",
    "            unique_list.append(item.metadata['source'])\n",
    "    return unique_list\n",
    "\n",
    "results = remove_duplicates(result['source_documents'])\n",
    "\n",
    "for s in results:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36d3a3-b71f-4e6b-9bd9-dc680d34aec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
